<p align="center">
<img src="https://user-images.githubusercontent.com/28100951/77494932-ec911d80-6e25-11ea-8fc7-1626af8a5212.png" width="600">
</p>

------------

<a id="top"></a>
### Contents
1. [Description](#1.0)
2. [Required packages - Kinetic Version](#2.0)
3. [Run GGCNN in Gazebo and RVIZ](#3.0)
4. [Sending commands through the action server](#4.0)
5. [Connecting with real UR5](#5.0)
6. [To do](#7.0)

------------

<a name="1.0"></a>
### 1.0 Description

This repository was created in order to develop an improved version of the [GGCNN]((https://github.com/dougsm/ggcnn_kinova_grasping)) Grasp Method created by Doug Morrison (2018).

> **_NOTE:_**  This package should be placed into your src folder. Please open an issue if you find any problem related to this package.

<a name="2.0"></a>
### 2.0 Required packages - Kinetic Version

> **_NOTE:_** Please access the grasp_project repository in order to check the required packages in the '2.0 Required packages' section. The same packages are used in this repository. You do not need to clone grasp_project repository.

- [grasp_project](https://github.com/caiobarrosv/grasp_project) - Created by Caio Viturino

#### Easy install

In order to install all the required packages easily, create a catkin workspace folder and then a src inside it.
```bash
mkdir -p ~/catkin_ws_new/src
```

Clone this repository into the src folder
```bash
cd ~/catkin_ws_new/src
git clone https://github.com/lar-deeufba/real-time-grasp
```

Run the install.sh file
```bash
cd ~/catkin_ws_new/src/real-time-grasp/install
sudo chmod +x ./install.sh
./install.sh #without sudo
```

### This repository also need the SSD512 implementation created by [czrcbl](https://github.com/czrcbl). Please follow the next procedures provided by him.

Wrapper for some object detection models trained on parts produced on a 3D printer.

Install bboxes before, you can install directly from `github`:
```bash
pip install git+https://github.com/czrcbl/bboxes
```

Or you can clone the repository and install on editable mode:
```bash
git clone https://github.com/czrcbl/bboxes
cd bboxes
git install -e .
```

<a name="3.0"></a>
### 3.0 Run GGCNN and SSD512 in Gazebo and RVIZ

Launch Gazebo first:
obs: The robot may not start correctly due to a hack method used to set initial joint positions in gazebo as mentioned in this [issue](https://github.com/ros-simulation/gazebo_ros_pkgs/issues/93#). If it happens, try to restart gazebo.
`bico` is a parameter that loads a 3D part in order to test the proposed method. We are not allowed to share this stl file since it is part of a private project. Therefore you will not be able to run the SSD512 net with the pre-trained `bico` part.
```bash
roslaunch real-time-grasp gazebo_ur5.launch bico:=true
```

Run this node and let the UR5 robot move to the front of the 3D printer. Then launch the next node (SSD512 node). 
The arm will only perform the grasp after the GGCNN node is running.
```bash
rosrun real-time-grasp command_GGCNN_ur5.py --gazebo
```

Start the SSD512 detection node. This node is responsible for detecting the object to be filtered.
```bash
roslaunch real-time-grasp detection.launch
```

Launch the node responsible for filtering the point cloud of the object detected by SSD512 network. The pointcloud and the depth image generated by this node will then be applied to the GGCNN node in order to identify the best possible grasp.
```bash
roslaunch real-time-grasp filter.launch
```

Launch RVIZ if you want to see the frame (object_detected) corresponding to the object detected by GGCNN and the point cloud.
In order to see the point cloud, please add pointcloud2 into the RVIZ and select the correct topic:
```bash
roslaunch real-time-grasp rviz_ur5.launch
```

Run the GGCNN. This node will publish a frame corresponding to the object detected by the GGCNN.
```bash
rosrun real-time-grasp SSD512_GGCNN.py
```

Running the following command will speed up the Gazebo simulation a little bit :)
```bash
rosrun real-time-grasp change_gazebo_properties.py
```

You might want to see the grasp or any other image. In order to do that, you can use the rqt_image_view.
```bash
rosrun rqt_image_view
```

<a name="4.0"></a>
### 4.0 Sending commands through the action server

If you want to test the position controller sending commands directly to the /'controller_command'/command topic use
the following:

```bash
rostopic pub -1 /pos_based_pos_traj_controller/command trajectory_msgs/JointTrajectory "header:
  seq: 0
  stamp:
    secs: 0
    nsecs: 0
  frame_id: ''
joint_names: ['shoulder_pan_joint', 'shoulder_lift_joint', 'elbow_joint', 'wrist_1_joint', 'wrist_2_joint', 'wrist_3_joint']
points:
  - positions: [1.57, 0, 0, 0, 0, 0]
    time_from_start: {secs: 1, nsecs: 0}"
```

<a name="5.0"></a>
### 5.0 Connecting with real UR5

Use the following command in order to connect with real UR5.
If you are using velocity control, do not use bring_up. Use ur5_ros_control instead.

```
roslaunch real-time-grasp ur5_ros_control.launch robot_ip:=192.168.131.13
```

Launch the real Intel Realsense D435
```
roslaunch real-time-grasp rs_d435_camera.launch
```

Launch the gripper control node
```
rosrun robotiq_2f_gripper_control Robotiq2FGripperRtuNode.py /dev/ttyUSB0
```

Launch the ggcnn node
```
rosrun real-time-grasp run_ggcnn_ur5.py --real
```

Launch the main node of the Intel Realsense D435
```
rosrun real-time-grasp command_GGCNN_ur5.py
```

If you want to visualize the depth or point cloud, you can launch RVIZ
```
roslaunch real-time-grasp rviz_ur5.launch
```

Firstly check the machine IP. The IP configured on the robot must have the last digit different.

```bash
ifconfig
```

Disable firewall

```bash
sudo ufw disable
```

Set up a static IP on UR5 according to the following figure

![config](https://user-images.githubusercontent.com/28100951/71323978-2ca7d380-24b8-11ea-954c-940b009cfd93.jpg)

Set up a connection on Ubuntu according to the following figure

![config_ethernet2](https://user-images.githubusercontent.com/28100951/71323962-fe29f880-24b7-11ea-86dc-756729932de4.jpg)

<a name="6.0"></a>
### 6.0 To do
#### April/20
- [] TBD
